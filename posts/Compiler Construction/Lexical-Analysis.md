---
title: "Lexical Analysis"
subtitle: "Create an AWS account and set up CLI/SDK access."
date: "2020-12-27"
---


# Lexical Analysis

- It is first phase of a compiler and also called scanning. The lexical analyser reads the stream of characters making up the source program and groups the characters into meaningful sequences called lexemes. 
- For each lexeme, the lexical analyser produces as output a token of the form (Token-name, attribute-value) that it passes on to the subsequent phase, syntax analysis.
- In the token, the first component token-name is an abstract symbol that is used during syntax analysis, and the second component attribute-value points to an entry in the symbol table for this token.
- Information from the symbol-table entry Is needed for semantic analysis and code generation.
- Blanks separating the lexemes would be discarded by the lexical analyser.

## Role of lexical analyser 
- The main task of the lexical analyser is to read the input characters of the source program, group them into lexemes, and produce as output a sequence of tokens for each lexeme in the source program.
- The stream of tokens is sent to the parser for syntax analysis.
- It is common for the lexical analyser to interact with the symbol table as well. When the lexical analyser discovers a lexeme constituting an identifier, it needs to enter that lexeme into the symbol table. In some cases, information regarding the kind of identifier may be read from the symbol table by the lexical analyser to assist it in determining the proper token it must pass to the parser.
- It also strips out comments and whitespace (blank, newline, tab, and perhaps other characters that are used to separate tokens in the input).
- It correlates error messages generated by the compiler with the source program.For instance, the lexical analyser may keep track of the number of newline characters seen, so it can associate a line number with each error message. In some compilers, the lexical analyser makes a copy of the source program with the error messages inserted at the appropriate positions. 



## Patterns, Tokens and Lexemes

**Token** 

It is basically a sequence of characters that are treated as a unit as it cannot be further broken down. In programming languages like C language- keywords (int, char, float, const, goto, continue, etc.) identifiers (user-defined names), operators (+, -, *,  /), delimiters/punctuators like comma (,), semicolon(;), braces ({ }), etc. , strings can be considered as tokens. This phase recognizes three types of tokens: Terminal Symbols (TRM)- Keywords and Operators, Literals (LIT), and Identifiers (IDN). Basically class of similar lexemes.

Example 1:

Tokens
int (keyword), a(identifier), =(operator), 10(constant) and ;(punctuation-semicolon)
Answer – Total number of tokens = 5

**Lexeme** 

It is a sequence of characters in the source code that are matched by given predefined language rules for every lexeme to be specified as a valid token.
Example:
main is lexeme of type identifier(token)
(,),{,} are lexemes of type punctuation(token)

**Pattern**

A set of strings in the input for which the same token is produced as output. This set of strings is described by a rule called a pattern associated with the token.

&nbsp;

| Criteria	| Token | Lexeme |	Pattern |
| --- | --- | --- | ---|
| Definition	| Token is basically a sequence of characters that are treated as a unit as it cannot be further broken down.	| It is a sequence of characters in the source code that are matched by given predefined language rules for every lexeme to be specified as a valid token. 	| It specifies a set of rules that a scanner follows to create a token.
| Interpretation of type Keyword 	| All the reserved keywords of that language(main, printf, etc.)	| int, goto	 | The sequence of characters that make the keyword. |
| Interpretation of type Identifier | 	name of a variable, function, etc	| main, a	| it must start with the alphabet, followed by the alphabet or a digit. | 
| Interpretation of type Operator	| all the operators are considered tokens.	| +, =	| +, = |
| Interpretation of type Punctuation  |	each kind of punctuation is considered a token. e.g. semicolon, bracket, comma, etc. | 	(, ), {, }	| (, ), {, } |
| Interpretation of type Literal |	a grammar rule or boolean literal.	| “Welcome to GeeksforGeeks!”	| any string of characters (except ‘ ‘) between ” and “ |


&nbsp;


Example -  position = initial + rate * 60 

The characters in this assignment could be grouped into the following lexemes and mapped into the following tokens passed on to the syntax analyser: 

- position is a lexeme that would be mapped into a token (id, 1), where id is an abstract symbol standing for identifier and 1 points to the symbol table entry for position. The symbol-table entry for an identifier holds information about the identifier, such as its name and type.  
- The assignment symbol = is a lexeme that is mapped into the token (=). Since this token needs no attribute-value, we have omitted the second component. We could have used any abstract symbol such as assign for the token-name, but for notational convenience we have chosen to use the lexeme itself as the name of the abstract symbol. 
- initial is a lexeme that is mapped into the token (id, 2) where 2 points to the symbol-table entry for initial. 
- \+ is a lexeme that is mapped into the token (+). 
- rate is a lexeme that is mapped into the token (id, 3), where 3 points to the symbol-table entry for rate. 
- \* is a lexeme that is mapped into the token (*).  
- 60 is a lexeme that is mapped into the token (60). 


## Need of Lexical Analysis as separate phase
- The separation of lexical and syntactic analysis often allows us to simplify at least one of these tasks. For example, a parser that had to deal with comments and whitespace as syntactic units would be considerably more complex than one that can assume comments and whitespace have already been removed by the lexical analyser.
- Compiler efficiency is improved. A separate lexical analyser allows us to apply specialized techniques that serve only the lexical task, not the job of parsing. In addition, specialized buffering techniques for reading input characters can speed up the compiler significantly.
- Compiler portability is enhanced. Input-device-specific peculiarities can be restricted to the lexical analyser. 


## Attributes of token -  
When more than one lexeme can match a pattern, the lexical analyser must provide the subsequent compiler phases additional information about the particular lexeme that matched. Thus, in many cases the lexical analyser returns to the parser not only a token name, but an attribute value that describes the lexeme represented by the token; the token name influences parsing decisions, while the attribute value influences translation of tokens after the parse. The most important example is the token id, where we need to associate with the token a great deal of information. Normally, information about an identifier — e.g., its lexeme, its type, and the location at which it is first found (in case an error message about that identifier must be issued) — is kept in the symbol table. Thus, the appropriate attribute value for an identifier is a pointer to the symbol-table entry for that identifier. 
Example: The token names and associated attribute values for the Fortran statement  E = M * C ** 2  are written below as a sequence of pairs. 

## Errors in lexical analysis

Type of errors in lexical analysis - 
- Identifiers that are very long
- Exceeding length of numeric constants like int i = 4567891;
- Numeric Constants which are ill-formed like int i = 456$44;
- Illegal charcters in source code like char x[]="Hello ";$

Error Recovery Strategy - 
- The simplest recovery strategy is "panic mode" recovery. We delete successive characters from the remaining input, until the lexical analyzer can and a well-formed token at the beginning of what input is left. This recovery technique may confuse the parser, but in an interactive computing environment it may be quite adequate.
- Delete one character from the remaining input.
- Insert a missing character into the remaining input.
- Replace a character by another character.
- Transpose two adjacent characters.



## Input Buffering